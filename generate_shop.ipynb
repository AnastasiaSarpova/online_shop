{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель задания:** Использовать Apache Spark для создания синтетического набора данных, который имитирует информацию о покупках в интернет-магазине.   \n",
    "Набор данных должен включать в себя информацию о заказах, включая дату заказа, идентификатор пользователя, название товара, количество и цену.  \n",
    "Сгенерированные данные будут использованы для последующего анализа покупательской активности и понимания потребительских трендов.  \n",
    "**Задачи**\n",
    "* Создать DataFrame с полями: Дата, UserID, Продукт, Количество, Цена.\n",
    "* Данные для поля Продукт генерируются из списка возможных товаров ( не меньше 5 товаров )\n",
    "* Количество и Цена должны генерироваться случайно в заданных пределах.\n",
    "* Дата должна быть в пределах последнего года.\n",
    "* UserID представляет собой случайное число, имитирующее идентификаторы пользователей.\n",
    "* Обратите внимание, что должна быть возможности изменять количество сгенерированных строк. Минимальное количество - 1000 строк.\n",
    "---\n",
    "*Сохранение данных:\n",
    "Сохранить сгенерированный DataFrame в формате CSV для последующего анализа.\n",
    "Результат выполнения задания (код генерации синтетических данных и созданный файл *.csv) необходимо выложить в github/gitlab и указать ссылку на Ваш репозиторий (не забудьте: репозиторий должен быть публичным).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pyspark.sql import SparkSession \n",
    "import pyspark.sql.functions as F\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName(\"Shop\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get('https://bystronom.ru/catalog/sales/supercena/')\n",
    "# считываем текст HTML-документа\n",
    "src = req.text\n",
    "# инициализируем html-код страницы\n",
    "soup = BeautifulSoup(src, 'html.parser')\n",
    "\n",
    "# достаем максимальное кол-во страниц\n",
    "pages_soup = soup.find_all('ul', {'class':'bx_pagination_page_list_num'})\n",
    "page_numbers = int(re.findall(r'PAGEN_1=(\\d+)', str(pages_soup))[-1])\n",
    "\n",
    "prices = []\n",
    "names = []\n",
    "\n",
    "# в каждом цикле считывем новую страницу и добавляем к спискам\n",
    "for num in range(1, page_numbers+1):\n",
    "    req = requests.get(f'https://bystronom.ru/catalog/sales/supercena/?PAGEN_1={num}&SIZEN_1=12')\n",
    "    # считываем текст HTML-документа\n",
    "    src = req.text\n",
    "    # инициализируем html-код страницы\n",
    "    soup = BeautifulSoup(src, 'html.parser')\n",
    "\n",
    "\n",
    "    names_soup = soup.find_all('div',{'class':'name'})\n",
    "    names.extend(list(map(lambda x: x.decode_contents(), names_soup)))\n",
    "\n",
    "    \n",
    "    prices_soup = soup.find_all('div',{'class':'price'})\n",
    "    for div in prices_soup:\n",
    "        match = re.search(r'(\\d+)<sup>(\\d+)', div.decode_contents()) #  `decode_contents()` предоставляет только внутреннее содержимое без внешнего тега\n",
    "        if match:\n",
    "            prices.append(float(match.group(0).replace('<sup>','.')))\n",
    "\n",
    "if len(names) == len(prices) > 0:\n",
    "    products = dict(zip(names, prices))\n",
    "else:\n",
    "    print('Разная длина списков')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cоздание серии дат\n",
    "# с начала года по текущую дату\n",
    "date_range = [[\"2024-01-01\",date.today()]]\n",
    "df = spark.createDataFrame(date_range,['start','end'])\n",
    "\n",
    "# Функция sequence позволяет конструировать массив, генерируя последовательность элементов от start до stop (включительно). \n",
    "# Поддерживаемые типы: byte, short, integer, long, date и timestamp.\n",
    "dates_df = df.selectExpr(\"sequence(to_date(start), to_date(end), interval 1 day) as date_sequence\")\n",
    "\n",
    "# explode - Возвращает новую строку для каждого элемента в заданном массиве или карте.\n",
    "dates_df = dates_df.selectExpr(\"explode(date_sequence) AS date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерируем данные и склеиваем в список\n",
    "def generation_store(volume=5):\n",
    "    user_id = np.random.randint(1,100000, size=volume).tolist()\n",
    "    product= np.random.choice(list(products.keys()), size=volume).tolist()\n",
    "    # подтягиваем цену из словаря для каждого продукта\n",
    "    price = list(map(lambda x: products.get(x), product))\n",
    "    cnt = np.random.randint(1,5, size=volume).tolist()\n",
    "    dt = np.random.choice(list(dates_df.rdd.flatMap(lambda x: x).collect()), size=volume).tolist()\n",
    "    \n",
    "    return user_id, product, price, cnt, dt\n",
    "client_id, product, price, cnt, dt = generation_store(volume=10000)  \n",
    "\n",
    "if len(client_id) == len(product) == len(price) == len(cnt) == len(dt):\n",
    "    shop_data = list(zip(dt, client_id, product, price, cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+-----+--------+\n",
      "|        dt|client_id|                item|price|quantity|\n",
      "+----------+---------+--------------------+-----+--------+\n",
      "|2024-04-24|    26231|Горошек БОНДЮЭЛЬ ...| 79.9|       1|\n",
      "|2024-02-01|    63049|Подгузники-трусик...|849.0|       1|\n",
      "|2024-03-05|    44526|Колготки ГЛАМУР В...|289.9|       4|\n",
      "|2024-04-07|    95720|Молоко ТОМСКОЕ МО...| 94.9|       2|\n",
      "|2024-02-16|    44606|Мак.изделия МАКФА...| 49.9|       2|\n",
      "+----------+---------+--------------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Создаем схему для DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"dt\", DateType(), True),\n",
    "    StructField(\"client_id\", IntegerType(), True), \n",
    "    StructField(\"item\", StringType(), True),\n",
    "    StructField(\"price\", FloatType(), True),\n",
    "    StructField(\"quantity\", IntegerType(), True)\n",
    "\n",
    "])\n",
    "# Создаем DataFrame с использованием схемы\n",
    "df_shop = spark.createDataFrame(shop_data, schema)\n",
    "df_shop.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# сохраняем в 1 файл csv\n",
    "df_shop.coalesce(1).write.csv('df_shop.csv')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
